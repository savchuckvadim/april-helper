import os

from dotenv import load_dotenv
from src.api.http.exceptions import AppException

from src.modules.ai.model.base_llm import LLMBase
from src.modules.ai.utils.langchain_helpers import extract_result

from langchain_ollama import OllamaLLM
from langchain_huggingface import HuggingFaceEmbeddings


class OllamaService:
    def __init__(self, model_name: str):
        self.model_name = model_name
        load_dotenv()
        self.ollama_url = os.getenv("OLLAMA_BASE_URL")
        print("OllamaService")
        self.llm = OllamaLLM(
            model="mistral",
            base_url=self.ollama_url or "http://45.12.74.239:11434",
        )
        print("OllamaService")
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-mpnet-base-v2"
        )

    async def resume(self, query: str):
        try:
            print("resume")

            # prompt = LLMBase.resume_prompt(with_history=True)
            # chain = prompt | self.llm  # –ü—Ä–æ—Å—Ç–æ prompt + LLM, –±–µ–∑ retriever
            # chat_history =  []
            # result = chain.invoke({
            #     "input": query,
            #     "chat_history": chat_history
            # })
            retriever = LLMBase.get_retriver(self.embeddings, self.model_name)
            print("retriever")
            print("üîó 2. –°–æ–±–∏—Ä–∞–µ–º —Ü–µ–ø–æ—á–∫—É —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏")

            chain = LLMBase.build_resume_chain(
                llm=self.llm, retriever=retriever, with_history=True
            )
            chat_history = []
            print("üöÄ 4. –ó–∞–ø—Ä–æ—Å")

            result = await chain.invoke(
                {"input": query, "chat_history": chat_history, "context": ""}
            )
            print(" –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω")
            return extract_result(result)

        except Exception as e:
            print(f"‚ùå Ollama recommendation error: {e}")
            raise AppException(status_code=500, detail=str(e))

    async def recomendation(self, query: str):
        try:
            # üß† 1. –ü–æ–ª—É—á–∞–µ–º retriever
            retriever = LLMBase.get_retriver(self.embeddings, self.model_name)
            print("retriever")
            print("üîó 2. –°–æ–±–∏—Ä–∞–µ–º —Ü–µ–ø–æ—á–∫—É —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏")

            chain = LLMBase.build_chain(
                llm=self.llm, retriever=retriever, with_history=True
            )

            # üí¨ 3. –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ (–ø–æ–∫–∞ –ø—É—Å—Ç–∞—è, –º–æ–∂–Ω–æ –ø–æ–∑–∂–µ –ø–æ–¥–∫–ª—é—á–∏—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏–µ)
            chat_history = []

            print("üöÄ 4. –ó–∞–ø—Ä–æ—Å")
            result = await chain.invoke(
                {"input": query, "chat_history": chat_history, "context": ""}
            )
            print(" –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω")
            # ‚úÖ 5. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return extract_result(result)

        except Exception as e:
            print(f"‚ùå Ollama recommendation error: {e}")
            raise AppException(status_code=500, detail=str(e))
