import os
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from src.modules.ai.utils.file_loader import FileLoader
from langchain.schema import Document


class ChromaService:
    @staticmethod
    def get_vectorstore(embeddings, embedding_id: str):
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—Ç—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
        db_path = f"chroma_db/{embedding_id}"

        # –ï—Å–ª–∏ –±–∞–∑–∞ —É–∂–µ –µ—Å—Ç—å ‚Äî –ø—Ä–æ—Å—Ç–æ –∑–∞–≥—Ä—É–∂–∞–µ–º
        if os.path.exists(db_path):
            return Chroma(persist_directory=db_path, embedding_function=embeddings)
        
        # –ò–Ω–∞—á–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Å–æ–∑–¥–∞—ë–º –±–∞–∑—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    

        print("üìÑ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞...")
        all_text = ""
        folder = os.path.abspath("retrive_data")


        documents = []  
        # text = extract_text_from_pdf(file_path)
        for filename in os.listdir(folder):
            path = os.path.join(folder, filename)
            try:
                content = FileLoader.extract_text(path)
                all_text += content + "\n"
                print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∏–ª–∏: {filename}")
                documents.append(Document(page_content=content, metadata={"source": filename}))

            except Exception as e:
                print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω {filename}: {e}")

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(documents)

    
        vectorstore = Chroma.from_documents(splits, embedding=embeddings, persist_directory=db_path)
        vectorstore.persist()  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã
    
        return vectorstore
